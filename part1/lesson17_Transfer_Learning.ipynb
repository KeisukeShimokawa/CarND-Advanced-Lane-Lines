{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson17 Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDrW5R9kv0xp+zxVSAxg9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeisukeShimokawa/CarND-Advanced-Lane-Lines/blob/master/part1/lesson17_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5GamoGzZkQQ",
        "colab_type": "text"
      },
      "source": [
        "# Lesson17 Transfer Learning\n",
        "\n",
        "GPUのようにスループットを高めることで、並列計算が多いディープラーニングで威力を発揮します。\n",
        "\n",
        "![](https://i.gyazo.com/bd904b4e0c16de166d5c3c72ea48f920.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpyIvbc8ZkMN",
        "colab_type": "text"
      },
      "source": [
        "ニューラルネットワークでは**転移学習**が威力が発揮します。しかし転移学習には以下のようにいくつかの用途が存在します。\n",
        "\n",
        "![](https://i.gyazo.com/926c3e736a64e250e636d31618b9cfeb.png)\n",
        "\n",
        "1. 新規データが少ない。元のデータに似ている。\n",
        "2. 新規データが少ない。元のデータに似ていない\n",
        "3. 新規データが多い。元のデータに似ている。\n",
        "4. 新規データが多い。元のデータに似ている。\n",
        "\n",
        "では以下のネットワークを使用して転移学習させていくことを想定して、それぞれのケースを想定してみましょう。\n",
        "\n",
        "![](https://i.gyazo.com/65dc3ad06e81842c1b16d1944ee73953.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4prAtVfGZkIu",
        "colab_type": "text"
      },
      "source": [
        "### Case1: Small, Similar Dataset\n",
        "\n",
        "![](https://i.gyazo.com/22eb3b9025de7d9c91287de29b864543.png)\n",
        "\n",
        "- 出力層を消す\n",
        "- 新規データのクラス数に合う線形結合層を追加\n",
        "- 追加した線形結合層を初期化し、学習済みモデルのパラメータを固定する\n",
        "- 線形結合層のパラメータを学習する\n",
        "\n",
        "過学習を避けるためにも学習済みのパラメータを固定したほうがいい。また画像の高次元な特徴も似ているため、事前学習済みのモデルは新規データによく似た特徴を補足できる能力があります。\n",
        "\n",
        "![](https://i.gyazo.com/dd629e09c6341c457d5f7bf4c6d03918.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgsC2pFKZkFN",
        "colab_type": "text"
      },
      "source": [
        "### Case2: Small, Different Dataset\n",
        "\n",
        "![](https://i.gyazo.com/0c6df1c739139029fd93126773128173.png)\n",
        "\n",
        "- ニューラルネットワークの入力近くの層を消去する\n",
        "- 残ったモデルに新規データのクラスに合う線形結合層を追加する\n",
        "- 線形結合層を初期化して、学習済みモデルのパラメータを固定する\n",
        "- 追加した線形結合層を学習する\n",
        "\n",
        "データセットが小さいため過学習に注意する必要があります。そのため事前学習済みモデルのパラメータは固定しておきます。\n",
        "\n",
        "異なるデータセットなので、より抽象的な特徴（高次な特徴）は似ている特徴を共有してはいません。そのため低次元な特徴のみを使用したいため、入力に近い層も消去していきます。\n",
        "\n",
        "![](https://i.gyazo.com/45ddf3392fdf0fb15144655ff11258b8.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxoE54StZkBd",
        "colab_type": "text"
      },
      "source": [
        "### Case3: Large, Similar Dataset\n",
        "\n",
        "![](https://i.gyazo.com/71547926fd73ac4606aed55b60a4c805.png)\n",
        "\n",
        "- 最終の線形結合層を削除して、新規データのクラスに合う線形結合層に変える\n",
        "- 追加した線形結合層を初期化する\n",
        "- 事前学習済みモデルのパラメータを使用して、残りのネットワークのパラメータを初期化する\n",
        "- 全体を学習しなおす\n",
        "\n",
        "データセットが大きい場合は過学習を心配する必要があまりないため、ネットワーク全体を学習しなおします。\n",
        "\n",
        "ただし高次の特徴は共有しているため、全体のネットワークをまだ使用することが可能です。\n",
        "\n",
        "![](https://i.gyazo.com/f25b469d9331404462bd6b96c3355ba1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8nvIi6GZj-V",
        "colab_type": "text"
      },
      "source": [
        "### Case4: Large, Different Dataset\n",
        "\n",
        "![](https://i.gyazo.com/6795f8cad9d3504ba27782f573febc6f.png)\n",
        "\n",
        "- 最終の線形結合層を削除して、新規データのクラスに合う線形結合層を追加する\n",
        "- ランダムに初期化したネットワークで学習しなおす\n",
        "- あるいは`Large & Similar`なデータセットの戦略を採用する\n",
        "\n",
        "データセットが似ていない場合に関しては、ネットワーク全体を学習しなおしたほうが学習が早いかもしれません。\n",
        "\n",
        "しかし最近の論文でもあったようにここの結論はいまだ出ていません。\n",
        "\n",
        "![](https://i.gyazo.com/5d5ee515c1b239bd9c7079a0ddd0f0fa.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpw4XSakZj69",
        "colab_type": "text"
      },
      "source": [
        "## LeNet\n",
        "\n",
        "元論文は[こちら](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQtLLtGmdKO",
        "colab_type": "text"
      },
      "source": [
        "## ImageNet\n",
        "\n",
        "ImageNetは1000クラス、合計1400万以上の画像を分類するタスクであり、様々なネットワークが採用されました。\n",
        "\n",
        "kerasでは[keras application](https://keras.io/applications/)を使用すれば、各モデルの事前学習済みのモデルを取得可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaJV0lITmdFZ",
        "colab_type": "text"
      },
      "source": [
        "## AlexNet\n",
        "\n",
        "AlexNetではネットワークを2つのGPUに乗せて、より大きなネットワークを構築しています。[元の論文](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)では、ネットワークを並列化させることで1.7%精度を向上させることができています。\n",
        "\n",
        "![](https://i.gyazo.com/5e0990a1e8bcfe0d98e5247aca0d8103.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t28Tac1EmdBf",
        "colab_type": "text"
      },
      "source": [
        "## VGG\n",
        "\n",
        "[元の論文](https://arxiv.org/abs/1409.1556)\n",
        "\n",
        "VGGは3x3畳み込み層と線形結合層を組み合わせた膨大なネットワークです。\n",
        "\n",
        "![](https://i.gyazo.com/946cc7d01a50d91226ee5ae0f55f2c54.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOrT9oSmc9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyO_kdMCmc5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# weightsはデフォルトが'imagenet'\n",
        "# weightsがパラメータランダム初期化のときはNone\n",
        "# include_top=Falseは、imagenet用の1000クラスの出力層を含めるかどうかを指定します。\n",
        "model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m3Kaknur4_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1c8ee76a-ca6a-4e04-b593-29e7f8dfa03f"
      },
      "source": [
        "!wget https://www.pakutaso.com/shared/img/thumb/tomcat1578_TP_V.jpg -O sample.jpg\n",
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-25 14:11:33--  https://www.pakutaso.com/shared/img/thumb/tomcat1578_TP_V.jpg\n",
            "Resolving www.pakutaso.com (www.pakutaso.com)... 180.235.251.31\n",
            "Connecting to www.pakutaso.com (www.pakutaso.com)|180.235.251.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 399961 (391K) [image/jpeg]\n",
            "Saving to: ‘sample.jpg’\n",
            "\n",
            "sample.jpg          100%[===================>] 390.59K   819KB/s    in 0.5s    \n",
            "\n",
            "2020-02-25 14:11:34 (819 KB/s) - ‘sample.jpg’ saved [399961/399961]\n",
            "\n",
            "sample_data  sample.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8-VJL7amc1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2c7a2806-c924-4d21-8395-a6266605dd79"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "img_path = 'sample.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "print(type(img), img.size)\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "print(type(x), x.shape)\n",
        "\n",
        "x = np.expand_dims(x, axis=0)\n",
        "print(type(x), x.shape)\n",
        "\n",
        "x = preprocess_input(x)\n",
        "print(type(x), x.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'> (224, 224)\n",
            "<class 'numpy.ndarray'> (224, 224, 3)\n",
            "<class 'numpy.ndarray'> (1, 224, 224, 3)\n",
            "<class 'numpy.ndarray'> (1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf8CrFnJmcxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4c01e250-4e56-4f3a-c52e-f7fcefa43358"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16, decode_predictions\n",
        "\n",
        "# モデルを読み込みます\n",
        "model = VGG16(weights='imagenet')\n",
        "\n",
        "# 前処理済みの画像の予測を行う\n",
        "predictions = model.predict(x)\n",
        "print(predictions.shape)\n",
        "\n",
        "print('predicted: ', decode_predictions(predictions, top=3)[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "(1, 1000)\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "predicted:  [('n02123045', 'tabby', 0.32574922), ('n02124075', 'Egyptian_cat', 0.19204272), ('n02123159', 'tiger_cat', 0.098262586)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YqRtFzRmcte",
        "colab_type": "text"
      },
      "source": [
        "## GoogLeNet\n",
        "\n",
        "[元の論文](https://arxiv.org/abs/1409.4842)\n",
        "\n",
        "インセプションのモジュールを導入することで、パラメータ数を削減してAlexNetと同等の速度で計算させることもできるうえ、AlexNetよりも精度は向上しています。\n",
        "\n",
        "![](https://i.gyazo.com/d310e15424390e27a89696735c9660d6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmYMZwuwZj3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "## Caution!! ##\n",
        "## 実際に使用する際は、画像のサイズを299x299に調整しましょう。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbaK5H83Zetd",
        "colab_type": "text"
      },
      "source": [
        "## ResNet\n",
        "\n",
        "[元の論文](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "ResNetでは、残差モジュールを導入することでより深い構造のネットワークを学習させることに成功しました。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCMxhw9pu08y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "550a7780-50e3-4af6-caa7-f8af4f3e0c3d"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "model = ResNet50(weights='imagenet', include_top=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg3b45ZRu1fD",
        "colab_type": "text"
      },
      "source": [
        "## Lab: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt2ti1lLvPiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フラグ設定を行う\n",
        "freeze_flag = True\n",
        "weight_flag = 'imagenet'\n",
        "preprocess_flag = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA-aFNCjvawf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# InceptionV3がサポートしている画像サイズは以下になります（kerasが対応しているもの）\n",
        "# 299x299x3\n",
        "# 139x139x3\n",
        "input_size = 139\n",
        "\n",
        "\n",
        "inception = InceptionV3(weights=weight_flag,\n",
        "                        include_top=False,\n",
        "                        input_shape=(input_size, input_size, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0dPEsczv1D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if freeze_flag:\n",
        "    # 層をループ処理で取得してフラグを設定する\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WABdhLsbwGft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc1da909-2628-435f-83d2-04d7ceeacd48"
      },
      "source": [
        "inception.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 139, 139, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 69, 69, 32)   864         input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 69, 69, 32)   96          conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 69, 69, 32)   0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 67, 67, 32)   9216        activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 67, 67, 32)   96          conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 67, 67, 32)   0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 67, 67, 64)   18432       activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 67, 67, 64)   192         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 67, 67, 64)   0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 33, 33, 64)   0           activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 33, 33, 80)   5120        max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 33, 33, 80)   240         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 33, 33, 80)   0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 31, 31, 192)  138240      activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 31, 31, 192)  576         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 31, 31, 192)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 15, 15, 192)  0           activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 15, 15, 64)   12288       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 15, 15, 64)   192         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 15, 15, 64)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 15, 15, 48)   9216        max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 15, 15, 96)   55296       activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 15, 15, 48)   144         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 15, 15, 96)   288         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 15, 15, 48)   0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 15, 15, 96)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 15, 15, 192)  0           max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 15, 15, 64)   12288       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 15, 15, 64)   76800       activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 15, 15, 96)   82944       activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 15, 15, 32)   6144        average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 15, 15, 64)   192         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 15, 15, 64)   192         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 15, 15, 96)   288         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 15, 15, 32)   96          conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 15, 15, 64)   0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 15, 15, 64)   0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 15, 15, 96)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 15, 15, 32)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 15, 15, 256)  0           activation_386[0][0]             \n",
            "                                                                 activation_388[0][0]             \n",
            "                                                                 activation_391[0][0]             \n",
            "                                                                 activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 15, 15, 64)   192         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 15, 15, 64)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 15, 15, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 15, 15, 96)   55296       activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 15, 15, 48)   144         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 15, 15, 96)   288         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 15, 15, 48)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 15, 15, 96)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 15, 15, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 15, 15, 64)   76800       activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 15, 15, 96)   82944       activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 15, 15, 64)   16384       average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 15, 15, 64)   192         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 15, 15, 64)   192         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 15, 15, 96)   288         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 15, 15, 64)   192         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 15, 15, 64)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 15, 15, 64)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 15, 15, 96)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 15, 15, 64)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 15, 15, 288)  0           activation_393[0][0]             \n",
            "                                                                 activation_395[0][0]             \n",
            "                                                                 activation_398[0][0]             \n",
            "                                                                 activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 15, 15, 64)   192         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 15, 15, 64)   0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 15, 15, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 15, 15, 96)   55296       activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 15, 15, 48)   144         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 15, 15, 96)   288         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 15, 15, 48)   0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 15, 15, 96)   0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 15, 15, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 15, 15, 64)   76800       activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 15, 15, 96)   82944       activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 15, 15, 64)   18432       average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 15, 15, 64)   192         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 15, 15, 64)   192         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 15, 15, 96)   288         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 15, 15, 64)   192         conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 15, 15, 64)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 15, 15, 64)   0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 15, 15, 96)   0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 15, 15, 64)   0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 15, 15, 288)  0           activation_400[0][0]             \n",
            "                                                                 activation_402[0][0]             \n",
            "                                                                 activation_405[0][0]             \n",
            "                                                                 activation_406[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 15, 15, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 15, 15, 64)   192         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 15, 15, 64)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 15, 15, 96)   55296       activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 15, 15, 96)   288         conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 15, 15, 96)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 7, 7, 96)     82944       activation_409[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 7, 7, 384)    1152        conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 7, 7, 96)     288         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 7, 7, 384)    0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 7, 7, 96)     0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_407[0][0]             \n",
            "                                                                 activation_410[0][0]             \n",
            "                                                                 max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 7, 7, 128)    384         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 7, 7, 128)    0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 7, 7, 128)    114688      activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 7, 7, 128)    384         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 7, 7, 128)    0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 7, 7, 128)    114688      activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 7, 7, 128)    384         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 7, 7, 128)    384         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 7, 7, 128)    0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 7, 7, 128)    0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 7, 7, 128)    114688      activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 7, 7, 128)    114688      activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 7, 7, 128)    384         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 7, 7, 128)    384         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 7, 7, 128)    0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 7, 7, 128)    0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 7, 7, 192)    172032      activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 7, 7, 192)    172032      activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 7, 7, 192)    576         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 7, 7, 192)    576         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 7, 7, 192)    576         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 7, 7, 192)    576         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 7, 7, 192)    0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 7, 7, 192)    0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 7, 7, 192)    0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 7, 7, 192)    0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_411[0][0]             \n",
            "                                                                 activation_414[0][0]             \n",
            "                                                                 activation_419[0][0]             \n",
            "                                                                 activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 7, 7, 160)    480         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 7, 7, 160)    0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 7, 7, 160)    179200      activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 7, 7, 160)    480         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 7, 7, 160)    0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 7, 7, 160)    179200      activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 7, 7, 160)    480         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 7, 7, 160)    480         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 7, 7, 160)    0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 7, 7, 160)    0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 7, 7, 160)    179200      activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 7, 7, 160)    179200      activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 7, 7, 160)    480         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 7, 7, 160)    480         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 7, 7, 160)    0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 7, 7, 160)    0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 7, 7, 192)    215040      activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 7, 7, 192)    215040      activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 7, 7, 192)    576         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 7, 7, 192)    576         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 7, 7, 192)    576         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 7, 7, 192)    576         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 7, 7, 192)    0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 7, 7, 192)    0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 7, 7, 192)    0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 7, 7, 192)    0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_421[0][0]             \n",
            "                                                                 activation_424[0][0]             \n",
            "                                                                 activation_429[0][0]             \n",
            "                                                                 activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 7, 7, 160)    480         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 7, 7, 160)    0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 7, 7, 160)    179200      activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 7, 7, 160)    480         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 7, 7, 160)    0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 7, 7, 160)    179200      activation_436[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 7, 7, 160)    480         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 7, 7, 160)    480         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 7, 7, 160)    0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 7, 7, 160)    0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 7, 7, 160)    179200      activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 7, 7, 160)    179200      activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 7, 7, 160)    480         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 7, 7, 160)    480         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 7, 7, 160)    0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 7, 7, 160)    0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 7, 7, 192)    215040      activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 7, 7, 192)    215040      activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 7, 7, 192)    576         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 7, 7, 192)    576         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 7, 7, 192)    576         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 7, 7, 192)    576         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 7, 7, 192)    0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 7, 7, 192)    0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 7, 7, 192)    0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 7, 7, 192)    0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_431[0][0]             \n",
            "                                                                 activation_434[0][0]             \n",
            "                                                                 activation_439[0][0]             \n",
            "                                                                 activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 7, 7, 192)    576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 7, 7, 192)    0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 7, 7, 192)    258048      activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 7, 7, 192)    576         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 7, 7, 192)    0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 7, 7, 192)    258048      activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 7, 7, 192)    576         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 7, 7, 192)    576         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 7, 7, 192)    0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 7, 7, 192)    0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 7, 7, 192)    258048      activation_442[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 7, 7, 192)    258048      activation_447[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 7, 7, 192)    576         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 7, 7, 192)    576         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 7, 7, 192)    0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 7, 7, 192)    0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 7, 7, 192)    258048      activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 7, 7, 192)    258048      activation_448[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 7, 7, 192)    576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 7, 7, 192)    576         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 7, 7, 192)    576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 7, 7, 192)    576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 7, 7, 192)    0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 7, 7, 192)    0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 7, 7, 192)    0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 7, 7, 192)    0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_441[0][0]             \n",
            "                                                                 activation_444[0][0]             \n",
            "                                                                 activation_449[0][0]             \n",
            "                                                                 activation_450[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 7, 7, 192)    576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 7, 7, 192)    0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 7, 7, 192)    258048      activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 7, 7, 192)    576         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 7, 7, 192)    0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 7, 7, 192)    258048      activation_454[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 7, 7, 192)    576         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 7, 7, 192)    576         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 7, 7, 192)    0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 7, 7, 192)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 3, 3, 320)    552960      activation_451[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 3, 3, 192)    331776      activation_455[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 3, 3, 320)    960         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 3, 3, 192)    576         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 3, 3, 320)    0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 3, 3, 192)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_452[0][0]             \n",
            "                                                                 activation_456[0][0]             \n",
            "                                                                 max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 3, 3, 448)    1344        conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 3, 3, 448)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 3, 3, 384)    1548288     activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 3, 3, 384)    1152        conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 3, 3, 384)    1152        conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 3, 3, 384)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 3, 3, 384)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 3, 3, 384)    442368      activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 3, 3, 384)    442368      activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 3, 3, 384)    442368      activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 3, 3, 384)    442368      activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 3, 3, 384)    1152        conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 3, 3, 384)    1152        conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 3, 3, 384)    1152        conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 3, 3, 384)    1152        conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 3, 3, 320)    960         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 3, 3, 384)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 3, 3, 384)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 3, 3, 384)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 3, 3, 384)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 3, 3, 192)    576         conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 3, 3, 320)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_459[0][0]             \n",
            "                                                                 activation_460[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 3, 3, 768)    0           activation_463[0][0]             \n",
            "                                                                 activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 3, 3, 192)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_457[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 3, 3, 448)    1344        conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 3, 3, 448)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 3, 3, 384)    1548288     activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 3, 3, 384)    1152        conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 3, 3, 384)    1152        conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 3, 3, 384)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 3, 3, 384)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 3, 3, 384)    442368      activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 3, 3, 384)    442368      activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 3, 3, 384)    442368      activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 3, 3, 384)    442368      activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 3, 3, 384)    1152        conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 3, 3, 384)    1152        conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 3, 3, 384)    1152        conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 3, 3, 384)    1152        conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 3, 3, 320)    960         conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 3, 3, 384)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 3, 3, 384)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 3, 3, 384)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 3, 3, 384)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 3, 3, 192)    576         conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 3, 3, 320)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_468[0][0]             \n",
            "                                                                 activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 3, 3, 768)    0           activation_472[0][0]             \n",
            "                                                                 activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 3, 3, 192)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_466[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_8[0][0]              \n",
            "                                                                 activation_474[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6tYSRvawKdy",
        "colab_type": "text"
      },
      "source": [
        "もしも最終層の線形結合層を除去して、新しい層を追加したい場合は`inception.layers.pop()`を使用して、最後の層を削除します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aciTGn31wtOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda\n",
        "import tensorflow as tf\n",
        "\n",
        "# 入力画像を格納する変数を用意しておきます。\n",
        "cifar_input = Input(shape=(32, 32, 3))\n",
        "\n",
        "# 入力画像をリサイズします。\n",
        "resized_input = Lambda(lambda image: tf.image.resize_images(image, \n",
        "                                                            (input_size, input_size)))(cifar_input)\n",
        "\n",
        "# リサイズした画像をモデルに渡たす\n",
        "inp = inception(resized_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfYBEbVxn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# モデルの最終層に新規データのクラス数分の線形結合層を追加します。\n",
        "x = GlobalAveragePooling2D()(inp)\n",
        "\n",
        "# Pooling層からそのまま入力を線形結合層に入力する\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "# 最後に予測を行う\n",
        "predictions = Dense(10, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy2fxeGayW3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "b79f0088-d403-420f-be86-cf8cc384763b"
      },
      "source": [
        "# ではModel APIを使用して定義した入力などの計算をまとめます。\n",
        "from keras.models import Model\n",
        "\n",
        "# 入力と出力を定義\n",
        "model = Model(inputs=cifar_input, outputs=predictions)\n",
        "\n",
        "# モデルを事前にコンパイル\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 139, 139, 3)       0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 22,857,002\n",
            "Trainable params: 22,822,570\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IK54XeUy96U",
        "colab_type": "text"
      },
      "source": [
        "### Keras Callback\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STon9h-0zHgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='save_path', \n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True)\n",
        "\n",
        "stopper = EarlyStopping(monitor='val_loss', min_delta=0.0003. patience=5)\n",
        "\n",
        "model.fit(callbacks=[checkpoint, stopper])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qna5SDoZz63z",
        "colab_type": "text"
      },
      "source": [
        "### GPU Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ODsoiVz7I6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e70ef03-6e18-4835-a197-ea6de30654dc"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "\n",
        "# One-hot encode the labels\n",
        "label_binarizer = LabelBinarizer()\n",
        "y_one_hot_train = label_binarizer.fit_transform(y_train)\n",
        "y_one_hot_val = label_binarizer.fit_transform(y_val)\n",
        "\n",
        "# Shuffle the training & test data\n",
        "X_train, y_one_hot_train = shuffle(X_train, y_one_hot_train)\n",
        "X_val, y_one_hot_val = shuffle(X_val, y_one_hot_val)\n",
        "\n",
        "# We are only going to use the first 10,000 images for speed reasons\n",
        "# And only the first 2,000 images from the test set\n",
        "X_train = X_train[:10000]\n",
        "y_one_hot_train = y_one_hot_train[:10000]\n",
        "X_val = X_val[:2000]\n",
        "y_one_hot_val = y_one_hot_val[:2000]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h41gkoIW0DG0",
        "colab_type": "text"
      },
      "source": [
        "[ImageDataGenerator Docs](https://faroit.github.io/keras-docs/2.0.9/preprocessing/image/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAcUpEXVz--r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use a generator to pre-process our images for ImageNet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "if preprocess_flag == True:\n",
        "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "else:\n",
        "    datagen = ImageDataGenerator()\n",
        "    val_datagen = ImageDataGenerator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YryuGvV0MG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "5c3e3509-9500-4168-e0bc-ea414b4823bd"
      },
      "source": [
        "# Train the model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "# Note: we aren't using callbacks here since we only are using 5 epochs to conserve GPU time\n",
        "model.fit_generator(datagen.flow(X_train, y_one_hot_train, batch_size=batch_size), \n",
        "                    steps_per_epoch=len(X_train)/batch_size, epochs=epochs, verbose=1, \n",
        "                    validation_data=val_datagen.flow(X_val, y_one_hot_val, batch_size=batch_size),\n",
        "                    validation_steps=len(X_val)/batch_size)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/5\n",
            "157/156 [==============================] - 62s 393ms/step - loss: 1.1417 - acc: 0.6267 - val_loss: 4.7563 - val_acc: 0.3090\n",
            "Epoch 2/5\n",
            "157/156 [==============================] - 37s 233ms/step - loss: 0.6002 - acc: 0.8033 - val_loss: 1.2357 - val_acc: 0.6645\n",
            "Epoch 3/5\n",
            "157/156 [==============================] - 36s 232ms/step - loss: 0.4628 - acc: 0.8504 - val_loss: 1.3015 - val_acc: 0.6240\n",
            "Epoch 4/5\n",
            "157/156 [==============================] - 36s 231ms/step - loss: 0.3417 - acc: 0.8828 - val_loss: 1.0556 - val_acc: 0.7195\n",
            "Epoch 5/5\n",
            "157/156 [==============================] - 36s 232ms/step - loss: 0.2894 - acc: 0.9047 - val_loss: 0.8752 - val_acc: 0.7250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6bdc7c1e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOAbxF4H0k_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_CG5-b0lZS",
        "colab_type": "text"
      },
      "source": [
        "## Additional Resources on Deep Learning\n",
        "\n",
        "Nice work reaching the end of the deep learning content! While you still have the project left to do here, we're also providing some additional resources and recent research on the topic that you can come back to if you have time later on.\n",
        "\n",
        "Reading research papers is a great way to get exposure to the latest and greatest in the field, as well as expand your learning. However, just like the project ahead, it's often best to learn by doing - if you find a paper that really excites you, try to implement it (or even something better) yourself!\n",
        "\n",
        "#### Optional Reading\n",
        "\n",
        "All of these are completely optional reading - you could spend hours reading through the entirety of these! We suggest moving onto the project first so you have what you’ve learned fresh on your mind, before coming back to check these out.\n",
        "\n",
        "We've categorized these papers to hopefully help you narrow down which ones might be of interest, as well as highlighted a couple key reads by category by including their Abstract section, which summarizes the paper.\n",
        "\n",
        "---\n",
        "\n",
        "### Behavioral Cloning\n",
        "\n",
        "The below paper shows one of the techniques Waymo has researched using imitation learning (aka behavioral cloning) to drive a car.\n",
        "\n",
        "[ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst](https://arxiv.org/abs/1812.03079) by M. Bansal, A. Krizhevsky and A. Ogale\n",
        "\n",
        "> Abstract: Our goal is to train a policy for autonomous driving via imitation learning that is robust enough to drive a real vehicle. We find that standard behavior cloning is insufficient for handling complex driving scenarios, even when we leverage a perception system for preprocessing the input and a controller for executing the output on the car: 30 million examples are still not enough. We propose exposing the learner to synthesized data in the form of perturbations to the expert's driving, which creates interesting situations such as collisions and/or going off the road. Rather than purely imitating all data, we augment the imitation loss with additional losses that penalize undesirable events and encourage progress -- the perturbations then provide an important signal for these losses and lead to robustness of the learned model. We show that the ChauffeurNet model can handle complex situations in simulation, and present ablation experiments that emphasize the importance of each of our proposed changes and show that the model is responding to the appropriate causal factors. Finally, we demonstrate the model driving a car in the real world.\n",
        "\n",
        "---\n",
        "\n",
        "### Object Detection and Tracking\n",
        "\n",
        "The below papers include various deep learning-based approaches to 2D and 3D object detection and tracking.\n",
        "\n",
        "[SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) by W. Liu, et. al.\n",
        "\n",
        "> Abstract: We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. [...] Experimental results [...] confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. [...]\n",
        "\n",
        "[VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection](https://arxiv.org/abs/1711.06396) by Y. Zhou and O. Tuzel\n",
        "\n",
        "> Abstract: Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. [...] Experiments on the KITTI car detection benchmark show that VoxelNet outperforms the state-of-the-art LiDAR based 3D detection methods by a large margin. Furthermore, our network learns an effective discriminative representation of objects with various geometries, leading to encouraging results in 3D detection of pedestrians and cyclists, based on only LiDAR.\n",
        "\n",
        "[Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net](http://openaccess.thecvf.com/content_cvpr_2018/papers/Luo_Fast_and_Furious_CVPR_2018_paper.pdf) by W. Luo, et. al.\n",
        "\n",
        "> Abstract: In this paper we propose a novel deep neural network that is able to jointly reason about 3D detection, tracking and motion forecasting given data captured by a 3D sensor. By jointly reasoning about these tasks, our holistic approach is more robust to occlusion as well as sparse data at range. Our approach performs 3D convolutions across space and time over a bird’s eye view representation of the 3D world, which is very efficient in terms of both memory and computation. Our experiments on a new very large scale dataset captured in several north american cities, show that we can outperform the state-of-the-art by a large margin. Importantly, by sharing computation we can perform all tasks in as little as 30 ms.\n",
        "\n",
        "---\n",
        "\n",
        "### Semantic Segmentation\n",
        "The below paper concerns a technique called semantic segmentation, where each pixel of an image gets classified individually!\n",
        "\n",
        "[SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/abs/1511.00561) by V. Badrinarayanan, A. Kendall and R. Cipolla\n",
        "\n",
        "> Abstract: We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. [...] The novelty of SegNet lies in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN and also with the well known DeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. [...] We show that SegNet provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures. [...]"
      ]
    }
  ]
}