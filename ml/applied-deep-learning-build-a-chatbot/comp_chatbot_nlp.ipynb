{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp-chatbot-nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkkCnOoeVvjvvz7lMf/HAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeisukeShimokawa/CarND-Advanced-Lane-Lines/blob/master/ml/applied-deep-learning-build-a-chatbot/comp_chatbot_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPbX6STh85xJ",
        "colab_type": "text"
      },
      "source": [
        "## Section24 Transformers\n",
        "\n",
        "### 24.1 introduction to Transformers\n",
        "\n",
        "![](https://i.gyazo.com/d5c131c855acf22d406c4604aa4e3ffc.png)\n",
        "\n",
        "![](https://i.gyazo.com/26640d0bac11c490b1428ed10db64f37.png)\n",
        "\n",
        "RNNは近距離をより重視\n",
        "\n",
        "![](https://i.gyazo.com/e1758b31a94e3bdfdddf124f175e98f9.png)\n",
        "\n",
        "Attentionの長所\n",
        "\n",
        "![](https://i.gyazo.com/142a9206eb9e0b549b320910589d69af.png)\n",
        "\n",
        "複数の個所を向くそれぞれのヘッドを用意\n",
        "\n",
        "![](https://i.gyazo.com/901330f92f21ff5928320f5743b33127.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8TELcmo85sZ",
        "colab_type": "text"
      },
      "source": [
        "### 24.2 input Embeddings\n",
        "\n",
        "![](https://i.gyazo.com/77a8fc18ae65a262ecd79f6ee5c83db1.png)\n",
        "\n",
        "従来はPaddingを行っている。\n",
        "\n",
        "![](https://i.gyazo.com/926839648f9a9f41307fec24e4a2fb3d.png)\n",
        "\n",
        "各単語に対応するWord Embeddingに変換する。\n",
        "\n",
        "![](https://i.gyazo.com/94a5da007b1a692295f46ca4023cedeb.png)\n",
        "\n",
        "![](https://i.gyazo.com/ae094c9f95f20df8ce38e4d9799a9aba.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSCeoCxs85oJ",
        "colab_type": "text"
      },
      "source": [
        "### 24.3 Positional Encoding\n",
        "\n",
        "Tranformersでは、時系列に沿ってデータを与えないため、各単語のどの位置で出現したのかその情報を計算する必要がある。\n",
        "\n",
        "![](https://i.gyazo.com/a5e8f5d0b584e41415d7037bcdedb15c.png)\n",
        "\n",
        "着想は三角関数の対応\n",
        "\n",
        "![](https://i.gyazo.com/f8215862a86280cdd1907ffda5ed52a5.png)\n",
        "\n",
        "![](https://i.gyazo.com/06ceed86be162fae36087fddcf5847a2.png)\n",
        "\n",
        "Word Embedding似合わせた次元数を指定する。\n",
        "\n",
        "![](https://i.gyazo.com/602c1bb32c600b26fd786a1b6f9215ad.png)\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/53ed598fb17f4d8f5d6ff3bf8efe5c03.png)\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/ac64c07add3a3786213b8eac634aa94d.png)\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/834e30540454a0458baee41b7464a67c.png)\n",
        "\n",
        "WordベクトルとPositional Encodingを使用して最終的にTransformerに入力するデータを生成します。しかしWordベクトルのほうが意味の情報を有しているため、単語ベクトルにはより重みを付けて意味がなくなってしまわないように計算を行っています。\n",
        "\n",
        "![](https://i.gyazo.com/ca08d9760ed6d7c86bf02b2c58ae4eae.png)\n",
        "\n",
        "![](https://i.gyazo.com/d72693ea3cf936681dd81651f3a0ee9d.png)\n",
        "\n",
        "#### 参考情報\n",
        "\n",
        "- [What is the positional encoding in the transformer model?](https://datascience.stackexchange.com/questions/51065/what-is-the-positional-encoding-in-the-transformer-model)\n",
        "- [Transformer Architecture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)\n",
        "- [reddit positional encoding](https://www.reddit.com/r/learnmachinelearning/comments/a35goa/positional_encoding/)\n",
        "- [experiment positional encoding](https://github.com/kaushalshetty/Positional-Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186e4bmu85kZ",
        "colab_type": "text"
      },
      "source": [
        "### 24.4 MultiHead Attention\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/3793d7236497a677ef52a830e0ae3b2d.png)\n",
        "\n",
        "複数の線型結合層を使用して、それぞれ異なる注意機構として動作させる。互いに異なる部分に注意付きを行っている。\n",
        "\n",
        "![](https://i.gyazo.com/a90384e80f62e5d71a04d573d3ed318b.png)\n",
        "\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/146ee5b73ace7aa7036fd5b3a143cf96.png)\n",
        "\n",
        "まずは同一の入力となる単語ベクトルに対して、線型結合層を適用してベクトルの次元を変換します。この際に、使用するヘッドの数に応じて、投影先のベクトルの次元を決定する。\n",
        "\n",
        "![](https://i.gyazo.com/0a5aab6a54f8e0f96adae4b6e9970577.png)\n",
        "\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/48678fb4428e06e672bffc251bd890a1.png)\n",
        "\n",
        "![](https://i.gyazo.com/c8a5d702ce8f39152dd65aa6b0d9ddec.png)\n",
        "\n",
        "![](https://i.gyazo.com/75f42e96978b741ec6a56200c387d5cb.png)\n",
        "\n",
        "![](https://i.gyazo.com/1456581356ea7cc8bde77e5c82035062.png)\n",
        "\n",
        "![](https://i.gyazo.com/17f4c46a36398bab61c85a4068b718c4.png)\n",
        "\n",
        "Dot積ではなく要素積でも計算可能。\n",
        "\n",
        "![](https://i.gyazo.com/1bc5d86fe59c1f88e3e523093f6a0ee3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVY1cIRf85gj",
        "colab_type": "text"
      },
      "source": [
        "### 24.5 Concat and Linear\n",
        "\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/557a99b416c0972f285a5d0ab360bf9d.png)\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/ac2bb39244bb1a7a833dd58382bc669e.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ0VhnRY74D5",
        "colab_type": "text"
      },
      "source": [
        "### 24.6 Residual Learning\n",
        "\n",
        "![](https://i.gyazo.com/b631778efc8b17691f52366a3771ed70.png)\n",
        "\n",
        "![](https://i.gyazo.com/ddaff51f2446c75480046228ea2f171d.png)\n",
        "\n",
        "![](https://i.gyazo.com/a4cfe4761d4229b787defc0095939502.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPIgboSJp6UN",
        "colab_type": "text"
      },
      "source": [
        "### 24.7 Layer Normalization\n",
        "\n",
        "![](https://i.gyazo.com/56889d251ca17948001e1a22d7a8a24e.png)\n",
        "\n",
        "![](https://i.gyazo.com/70c8f656d1c2c3117d26f2c54e0f9d90.png)\n",
        "\n",
        "![](https://i.gyazo.com/8b03300ce20a34bde1341c70659493ec.png)\n",
        "\n",
        "- [Batch Normalizationとその派生の整理\n",
        "2019/6/16](https://gangango.com/2019/06/16/post-573/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAKQGXMzrgAK",
        "colab_type": "text"
      },
      "source": [
        "### 24.8 Feed Forward\n",
        "\n",
        "![](https://i.gyazo.com/2539ff7c359dca69d4aac997b87d9f04.png)\n",
        "\n",
        "![](https://i.gyazo.com/b71fad6de216e4ed95cb38d3915c6a47.png)\n",
        "\n",
        "![](https://i.gyazo.com/a2f9ccc57ca934e170b06057ab0342af.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9x4kde6p55s",
        "colab_type": "text"
      },
      "source": [
        "### 24.9 Masked MultiHead Attention\n",
        "\n",
        "![](https://i.gyazo.com/051ac0120060a9e5d86869bfae35d45d.png)\n",
        "\n",
        "\n",
        "![](https://i.gyazo.com/49d2cfaa935853bf425397fdb956a81c.png) ![](https://i.gyazo.com/d4af70f2b17698907c80ae6d3144089e.png) ![](https://i.gyazo.com/fcef7a80df21956a806091b5c01b01bf.png)\n",
        "\n",
        "![](https://i.gyazo.com/97314f961082b247c001163c6f21b0de.png)\n",
        "\n",
        "![](https://i.gyazo.com/edecb40f209f3a5dd2531e1fcb78814a.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVjEKb_hQwgq",
        "colab_type": "text"
      },
      "source": [
        "### 24.10 MultiHead Attention in Decoder\n",
        "\n",
        "![](https://i.gyazo.com/cc272c0776dd50f76228897e97fd158e.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irr6BXwJQX43",
        "colab_type": "text"
      },
      "source": [
        "### 24.11 Cross Entropy Loss\n",
        "\n",
        "![](https://i.gyazo.com/04a196a1687f56385652c6a641b9f237.png)\n",
        "\n",
        "![](https://i.gyazo.com/104f959c855c275fa5f21936f017aa43.png)\n",
        "\n",
        "![](https://i.gyazo.com/7dc03051c8f0dd3295c65a575c175808.png)\n",
        "\n",
        "![](https://i.gyazo.com/61b53e5c78da2d01703ac0152755f116.png)\n",
        "\n",
        "![](https://i.gyazo.com/90c2cb2f4612315d8b82dd144ba9b0ae.png)\n",
        "\n",
        "![](https://i.gyazo.com/688913adc294bc6dfdc5f9476f4c2282.png)\n",
        "\n",
        "![](https://i.gyazo.com/521f6f754467c63422144e2eb40956ff.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8zUAHgeTXLj",
        "colab_type": "text"
      },
      "source": [
        "### 24.12 KL Divergence Loss\n",
        "\n",
        "![](https://i.gyazo.com/6b735895c8de08760f4a8e3f904458ab.png)\n",
        "\n",
        "![](https://i.gyazo.com/6d8eb084bac346966000a808443efdc9.png)\n",
        "\n",
        "![](https://i.gyazo.com/c6529dda9affdd223dca12c1523ea874.png)\n",
        "\n",
        "![](https://i.gyazo.com/360a18a93b2205b9ebd1487abdcba8e2.png)\n",
        "\n",
        "![](https://i.gyazo.com/0e2092bc0085771a119984d9392a16ee.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pwbiNyxUyzu",
        "colab_type": "text"
      },
      "source": [
        "### 24.13 Label Smoothing\n",
        "\n",
        "![](https://i.gyazo.com/1657a804a3e6430b8e67547ab93e8547.png)\n",
        "\n",
        "![](https://i.gyazo.com/8bb2a98fce9bbd3253001b62e1a07f31.png)\n",
        "\n",
        "![](https://i.gyazo.com/bd809bd372e284c1ebdceae27c104330.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zcljd1vyVl14",
        "colab_type": "text"
      },
      "source": [
        "### 24.14 Dropout\n",
        "\n",
        "![](https://i.gyazo.com/105690da3223dc0c8e502a242feeb1ee.png)\n",
        "\n",
        "![](https://i.gyazo.com/757a1b659d09e05783f072f1538d5dec.png)\n",
        "\n",
        "![](https://i.gyazo.com/6fce9f437eab11f3111662e4b0094f8e.png)\n",
        "\n",
        "![](https://i.gyazo.com/bf30ec53b6e249ee17151a6906debbf1.png)\n",
        "\n",
        "![](https://i.gyazo.com/070fe28b0e3158abc5a017708a6dcacd.png)\n",
        "\n",
        "![](https://i.gyazo.com/cce90c51e225a81b475fab14ea550293.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOTDS-xSYJJV",
        "colab_type": "text"
      },
      "source": [
        "### 24.15 Learning Rate WarmUp\n",
        "\n",
        "![](https://i.gyazo.com/87702a8fb856978713a6573fe5eee7c3.png)\n",
        "\n",
        "![](https://i.gyazo.com/9a581219e2424688bc80a8e8904ac958.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgDTWEFFZ-EU",
        "colab_type": "text"
      },
      "source": [
        "## Section25 Chatbot\n",
        "\n",
        "[code](https://github.com/fawazsammani/chatbot-transformer)\n",
        "\n",
        "### 25.1 Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXlLb6BBZ9rm",
        "colab_type": "code",
        "outputId": "43b310e3-ff32-4476-e560-cb288d5dc7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip -O cornell_movie_dialogs_corpus.zip\n",
        "!unzip -q -o cornell_movie_dialogs_corpus.zip\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-14 08:04:39--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  2.61MB/s    in 4.1s    \n",
            "\n",
            "2020-03-14 08:04:44 (2.31 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n",
            "'cornell movie-dialogs corpus'\t    __MACOSX\n",
            " cornell_movie_dialogs_corpus.zip   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAkz4D4saG6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset\n",
        "import math\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89BYYXzQZEDi",
        "colab_type": "code",
        "outputId": "888bb500-d36e-468c-ce20-172d5f5a383a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAOxIdbxYGPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_movie_conv  = \"cornell movie-dialogs corpus/movie_conversations.txt\"\n",
        "corpus_movie_lines = \"cornell movie-dialogs corpus/movie_lines.txt\"\n",
        "max_len = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Xolf0YYS0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(corpus_movie_conv, encoding='utf-8', errors='ignore') as c:\n",
        "    conv = c.read().split('\\n')\n",
        "\n",
        "with open(corpus_movie_lines, encoding='utf-8', errors='ignore') as l:\n",
        "    lines = l.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dug1_qE8YfZi",
        "colab_type": "code",
        "outputId": "d9b6e561-c511-4a81-e4ff-e87bcbc1e128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "conv[:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
              " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
              " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P9Dt2s1Y81j",
        "colab_type": "code",
        "outputId": "05d4dcea-bb69-4489-e564-d333e706efcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "lines[:3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
              " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
              " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8uxof-NZPWq",
        "colab_type": "code",
        "outputId": "55909fa6-7bc4-43c4-f072-78b68e630a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(conv[0].split(' +++$+++ ')[-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEZnwd8YG4TA",
        "colab_type": "text"
      },
      "source": [
        "### 25.2 Create Line Dist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4m-mdY0ZIwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines_dict = {}\n",
        "for line in lines:\n",
        "    opjects = line.split(' +++$+++ ')\n",
        "    lines_dict[opjects[0]] = opjects[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC7Cc5Rpbgg6",
        "colab_type": "code",
        "outputId": "091c26cd-39be-44fd-9823-f6b4eab7daa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines_dict['L1045']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'They do not!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5n6XDrHbc5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punc(string):\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%~&*_~'''\n",
        "    no_punc = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punc = no_punc + char\n",
        "    return no_punc.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tujWYq07b_7T",
        "colab_type": "code",
        "outputId": "afe961c7-97fb-477e-8b00-cd82f270b303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "s = \"\"\n",
        "s = s + \"g\"\n",
        "print(s)\n",
        "s = s + \"u\"\n",
        "print(s)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "g\n",
            "gu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL-lgm9Hbz1v",
        "colab_type": "code",
        "outputId": "fc577fc7-c225-4114-d005-6cfc7a079605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "remove_punc(\"tgyusj!(@)ihdys\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tgyusjihdys'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJe9PZ0iG0mI",
        "colab_type": "text"
      },
      "source": [
        "### 25.3 Create Q&A Pair Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTEUrMZlFtkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a87114d-1d29-4ecd-f728-1c53459f062a"
      },
      "source": [
        "conv[0].split(' +++$+++ ')[-1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['L194', 'L195', 'L196', 'L197']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlCXxVN1cT4a",
        "colab_type": "code",
        "outputId": "31b207b9-4355-45fa-d43e-9941d16fa217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "eval(conv[0].split(' +++$+++ ')[-1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L194', 'L195', 'L196', 'L197']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdtA4M61cr-_",
        "colab_type": "code",
        "outputId": "273baa0f-941f-485e-f7fe-e6466c10a9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "lines_dict['L194']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLA7wCdYd2Pc",
        "colab_type": "code",
        "outputId": "4a13cd05-9d74-494c-9ddc-785adb71e53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "lines_dict['L194'].strip().split()[:max_len]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can',\n",
              " 'we',\n",
              " 'make',\n",
              " 'this',\n",
              " 'quick?',\n",
              " 'Roxanne',\n",
              " 'Korrine',\n",
              " 'and',\n",
              " 'Andrew',\n",
              " 'Barrett',\n",
              " 'are',\n",
              " 'having',\n",
              " 'an',\n",
              " 'incredibly',\n",
              " 'horrendous',\n",
              " 'public',\n",
              " 'break-',\n",
              " 'up',\n",
              " 'on',\n",
              " 'the',\n",
              " 'quad.',\n",
              " 'Again.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpdiAPQMc7Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs = []\n",
        "for con in conv:\n",
        "\n",
        "    if con == '':\n",
        "        continue\n",
        "\n",
        "    ids = eval(con.split(' +++$+++ ')[-1])\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        if i == len(ids) - 1:\n",
        "          break\n",
        "\n",
        "        first = remove_punc(lines_dict[ids[i]].strip())\n",
        "        second = remove_punc(lines_dict[ids[i+1]].strip())\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "\n",
        "        pairs.append(qa_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6u8pRaiGq3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "16f317ec-d529-4721-caab-d4f11077692f"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['can',\n",
              "  'we',\n",
              "  'make',\n",
              "  'this',\n",
              "  'quick',\n",
              "  'roxanne',\n",
              "  'korrine',\n",
              "  'and',\n",
              "  'andrew',\n",
              "  'barrett',\n",
              "  'are',\n",
              "  'having',\n",
              "  'an',\n",
              "  'incredibly',\n",
              "  'horrendous',\n",
              "  'public',\n",
              "  'break',\n",
              "  'up',\n",
              "  'on',\n",
              "  'the',\n",
              "  'quad',\n",
              "  'again'],\n",
              " ['well',\n",
              "  'i',\n",
              "  'thought',\n",
              "  'wed',\n",
              "  'start',\n",
              "  'with',\n",
              "  'pronunciation',\n",
              "  'if',\n",
              "  'thats',\n",
              "  'okay',\n",
              "  'with',\n",
              "  'you']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqnUdgbTGq65",
        "colab_type": "text"
      },
      "source": [
        "### 25.4 Create Word ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY4gDstLGq-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "    word_freq.update(pair[0])\n",
        "    word_freq.update(pair[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWTa8KAII5c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_word_freq = 5\n",
        "words = [ w for w in word_freq.keys() if word_freq[w] > min_word_freq]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCmBuXOfI5-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "991747c5-08e9-4698-e63c-23b68ecefbf0"
      },
      "source": [
        "for i, word in enumerate(words):\n",
        "    print(i)\n",
        "    print(word)\n",
        "    if i == 5:\n",
        "        break"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "can\n",
            "1\n",
            "we\n",
            "2\n",
            "make\n",
            "3\n",
            "this\n",
            "4\n",
            "quick\n",
            "5\n",
            "and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtV9CwJwGrBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first word index starts at 1\n",
        "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "word_map['<unk>'] = len(word_map) + 1\n",
        "word_map['<start>'] = len(word_map) + 1\n",
        "word_map['<end>'] = len(word_map) + 1\n",
        "word_map['<pad>'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9dMNb8VIW2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa9c49de-06fe-4013-f507-45aef99889b9"
      },
      "source": [
        "word_map['can']"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZzdjrl5Ic_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "401c0fce-142d-4624-a41f-38629bcb3132"
      },
      "source": [
        "print('Total words are {}'.format(len(word_map)))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words are 18190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpLGgZIXI_E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('WORDMAP_CORPUS.json', 'w') as f:\n",
        "    json.dump(word_map, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUC8Wxd6JHtd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26ca68eb-bf62-4d63-dec4-3f748dd853c6"
      },
      "source": [
        "!ls | grep WORDMAP"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WORDMAP_CORPUS.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbDngZsJJJZN",
        "colab_type": "text"
      },
      "source": [
        "### 25.5 Create Encoding Sentence Function for Q&A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyo6pRFqJJWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + \\\n",
        "            [word_map['<pad>']] * (max_len - len(words))\n",
        "\n",
        "    return enc_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFZKePOrJJTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_reply(words, word_map):\n",
        "    enc_c = [word_map['<start>']] + \\\n",
        "            [word_map.get(word, word_map['<unk>']) for word in words] + \\\n",
        "            [word_map['<end>']] + \\\n",
        "            [word_map['<pad>']] * (max_len - len(words))\n",
        "\n",
        "    return enc_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIA5KmtyJJQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "11f12b4c-c8bc-497c-ca2d-5506fb7632b3"
      },
      "source": [
        "pairs[0][0]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['can',\n",
              " 'we',\n",
              " 'make',\n",
              " 'this',\n",
              " 'quick',\n",
              " 'roxanne',\n",
              " 'korrine',\n",
              " 'and',\n",
              " 'andrew',\n",
              " 'barrett',\n",
              " 'are',\n",
              " 'having',\n",
              " 'an',\n",
              " 'incredibly',\n",
              " 'horrendous',\n",
              " 'public',\n",
              " 'break',\n",
              " 'up',\n",
              " 'on',\n",
              " 'the',\n",
              " 'quad',\n",
              " 'again']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3IMar_KJJMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "95b61451-454c-4a7e-9579-61285d874e7d"
      },
      "source": [
        "encode_question(pairs[0][0], word_map)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 18187,\n",
              " 18187,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 18187,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18187,\n",
              " 18,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeCpjascJJJ1",
        "colab_type": "text"
      },
      "source": [
        "### 25.6 Create FUnction for Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yIlf4iuJJGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs_encoded = []\n",
        "for pair in pairs:\n",
        "    ques = encode_question(pair[0], word_map)\n",
        "    ans = encode_reply(pair[1], word_map)\n",
        "\n",
        "    pairs_encoded.append([ques, ans])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmifVogvJJDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "29d60b13-19c8-4c1c-cb2a-288b15a7a26d"
      },
      "source": [
        "pairs_encoded[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  18187,\n",
              "  18187,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  18187,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18187,\n",
              "  18,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " [18188,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  18187,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  24,\n",
              "  28,\n",
              "  18189,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXdSAtRpJJAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('pairs_encoded.json', 'w') as f:\n",
        "    json.dump(pairs_encoded, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zycDcmsXJIrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8c588033-ce52-4274-f739-78158c393bfd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'cornell movie-dialogs corpus'\t    __MACOSX\t\t sample_data\n",
            " cornell_movie_dialogs_corpus.zip   pairs_encoded.json\t WORDMAP_CORPUS.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILSteZbyLE_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, path='pairs_encoded.json'):\n",
        "        self.pairs = json.load(open(path))\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        question = torch.LongTensor(self.pairs[i][0])\n",
        "        reply = torch.LongTensor(self.pairs[i][1])\n",
        "\n",
        "        return question, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VvcsVEwMMo1",
        "colab_type": "text"
      },
      "source": [
        "### 25.7 Data Loading and Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Ge_2BzMMlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(Dataset(), \n",
        "                                           batch_size=100, \n",
        "                                           shuffle=True,\n",
        "                                           pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUvLXZV7MMiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question, reply = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9g9NAE0MLuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c045b17f-f96e-4d7c-a1f2-994f39b5dea2"
      },
      "source": [
        "question.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egRldq1rMtAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "692f3239-2a7b-4042-930f-54cbd2677016"
      },
      "source": [
        "reply.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 27])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqAp817TNnsm",
        "colab_type": "text"
      },
      "source": [
        "create mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_6IxidNiki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d1e1cdc4-ce7d-42b3-ab48-ca2596c887cc"
      },
      "source": [
        "size = 5\n",
        "torch.ones(size, size)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ6PqWJTNm_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "25f0f2a6-b090-4029-df47-727d82fe3c4a"
      },
      "source": [
        "size = 5\n",
        "torch.triu(torch.ones(size, size))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [0., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgLx4fqzNuBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6ad1421b-2ae9-4063-b5ef-29ad3822d2db"
      },
      "source": [
        "size = 5\n",
        "torch.triu(torch.ones(size, size)).transpose(0, 1)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lygILSuMOGEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ee309adb-6dc8-4a45-dd86-c694cb93ea4d"
      },
      "source": [
        "question[0]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,  255,  406, 4211,   91,  657,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbUj2QIOJ8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a37c52cc-1c8f-41dd-e8dc-c11250e77e29"
      },
      "source": [
        "question[0]!=0"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWjRgESDOOmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm_9ziqXMuFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_masks(question, reply_input, reply_target):\n",
        "    \"\"\"\n",
        "    sentence:     <start> I slept last night <end>\n",
        "    reply_input:  <start> I slept last night\n",
        "    reply_target:         I slept last night <end>\n",
        "    \"\"\"\n",
        "\n",
        "    def subsequence_mask(size):\n",
        "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
        "        return mask.unsqueeze(0)\n",
        "\n",
        "    question_mask = (question!=0).to(device)\n",
        "    question_mask = question_mask.unsqueeze(1)      # (batch_size, 1, 1, max_words)\n",
        "\n",
        "    reply_input_mask = reply_input!=0\n",
        "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
        "    reply_input_mask = reply_input_mask & subsequence_mask(reply_input.size(-1)).type_as(reply_input_mask.data)\n",
        "    # (batch_size, max_words, max_words)\n",
        "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words, max_words)\n",
        "    reply_target_mask = reply_target!=0               # (batch_size, max_words)\n",
        "\n",
        "    return question_mask, reply_input_mask, reply_target_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP5mdLvkNhrQ",
        "colab_type": "text"
      },
      "source": [
        "### 25.8 Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_WJ0qbWNhu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKUX0KrcNhyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXd94BlYNh12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}